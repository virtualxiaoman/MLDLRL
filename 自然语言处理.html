<!DOCTYPE html><html><head>
      <title>自然语言处理</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\HP\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.13\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="coloree0000-1-简介-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#ee0000"><mn>1.</mn><mtext>&nbsp;简介</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{ee0000} 1.\ 简介</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#ee0000;">1.</span><span class="mspace" style="color:#ee0000;"><span style="color:#ee0000;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#ee0000;">简介</span></span></span></span> </h1>
<h2 id="color66ccff-11-方法-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>1.1</mn><mtext>&nbsp;方法</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 1.1\ 方法</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">1.1</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">方法</span></span></span></span> </h2>
<ul>
<li>符号主义：正则表达式、语言学</li>
<li>统计方法：N-gram、HMM、PCFG</li>
<li>联结主义：神经网络、深度学习</li>
</ul>
<h2 id="color66ccff-12-参考资料-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>1.2</mn><mtext>&nbsp;参考资料</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 1.2\ 参考资料</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">1.2</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">参考资料</span></span></span></span> </h2>
<p><a href="https://hnlp.boyuai.com/">动手学NLP</a>：据说要出电子书，但是遥遥无期啊，最后还是买了纸质的。</p>
<h1 id="coloree0000-2-文本规范化-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#ee0000"><mn>2.</mn><mtext>&nbsp;文本规范化</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{ee0000} 2.\ 文本规范化</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#ee0000;">2.</span><span class="mspace" style="color:#ee0000;"><span style="color:#ee0000;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#ee0000;">文本规范化</span></span></span></span> </h1>
<h2 id="color66ccff-21-分词-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>2.1</mn><mtext>&nbsp;分词</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 2.1\ 分词</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">2.1</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">分词</span></span></span></span> </h2>
<h3 id="color39c5bb-211-英文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.1.1</mn><mtext>&nbsp;英文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.1.1\ 英文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.1.1</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">英文</span></span></span></span> </h3>
<p>特点：词间有空格分隔。</p>
<ol>
<li>
<p><strong>基于空格：</strong><code>tokens = sentence.split(' ')</code></p>
</li>
<li>
<p><strong>基于正则表达式：</strong></p>
</li>
</ol>
<ul>
<li><strong>忽略所有标点：</strong><code>tokens = re.findall(r'\w+', sentence)</code>。（只替换标点而不分词：<code>re.sub(r'[^\w\s]', '', sentence)</code>）</li>
<li><strong>智能分词：</strong><code>\.\.\.|\$?\d+(?:\.\d+)?%?|(?:\w+\.)+\w+(?:\.)*|\w+(?:[-']\w+)*|\S\w*</code><br>
其中：<br>
<code>\.\.\.</code>匹配省略号，<br>
<code>\$?\d+(?:\.\d+)?%?</code>匹配美元货币，<br>
<code>(?:\w+\.)+\w+(?:\.)*</code>匹配缩写或网址，<br>
<code>\w+(?:[-']\w+)*</code>匹配单词，<br>
<code>\S\w*</code>匹配连字符(比如It's的's或者单个标点符号)。<br>
最终效果是：</li>
</ul>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>sentence <span class="token operator">=</span> <span class="token string">"Did you spend $3.4 on arxiv.org for your pre-print?   No, it's free! It's ..."</span>
pattern <span class="token operator">=</span> <span class="token string">r"\.\.\.|\$?\d+(?:\.\d+)?%?|(?:\w+\.)+\w+(?:\.)*|\w+(?:[-']\w+)*|\S\w*"</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出：['Did', 'you', 'spend', '$3.4', 'on', 'arxiv.org', 'for', 'your', 'pre-print', '?', 'No', ',', "it's", 'free', '!', "It's", '...']</span>
</code></pre><p>注：<code>(?:...)</code>是非捕获组，也就是匹配的时候要匹配到这个，但是不把这个组的内容放到匹配结果里面，比如<code>re.findall(r'(?:\w+)-(\d+)', 'abc-123 def-456')</code>的结果是<code>['123', '456']</code>。</p>
<div align="center">
<img src="assets/自然语言处理/images/image-1.png" width="80%">
</div>
<h3 id="color39c5bb-212-中文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.1.2</mn><mtext>&nbsp;中文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.1.2\ 中文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.1.2</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">中文</span></span></span></span> </h3>
<p>特点：词间无空格分隔。</p>
<ol>
<li><strong>基于监督学习的序列标注模型：</strong> CRF</li>
<li><strong>基于子词的分词：</strong> 字节对编码BPE、一元语言建模分词unigram language modeling tokenization、词片WordPiece。</li>
</ol>
<p style="color:#EC407A; font-weight:bold">BPE</p>
<ol>
<li><strong>初始化：</strong> 将所有字符作为词并在最后面加上<code>_</code>，然后统计每个前后相连字符对的频率。比如将词<code>beijing</code>拆分成字符<code>['b', 'e', 'i', 'j', 'i', 'n', 'g', '_']</code>，统计语料库里所有的词<code>'be', 'ei', 'ij', 'ji', 'in', 'ng', 'g_'</code>的频率。</li>
<li><strong>合并：</strong> 合并频率最高的字符对<code>merge_key</code>，更新字符对的频率。假设<code>merge_key</code>是<code>ng</code>，那么之前的<code>'n', 'g'</code>会被替换为<code>'ng'</code>。</li>
<li><strong>重复：</strong> 重复步骤2，直到达到指定的词表大小或达到指定迭代次数。</li>
</ol>
<details>
<summary><span style="color:#009688; font-weight:bold">点击展开完整代码</span></summary>
<p>代码实现：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 1. 语料库</span>
corpus <span class="token operator">=</span> <span class="token string">"nan nan nan nan nan nanjing nanjing beijing beijing beijing beijing beijing beijing dongbei dongbei dongbei bei bei"</span>
tokens <span class="token operator">=</span> corpus<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

<span class="token comment"># 构建基于字符的初始词表</span>
vocabulary <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>  <span class="token comment"># {'a', ' ', 'j', 'd', 'o', 'e', 'g', 'b', 'n', 'i'}</span>
vocabulary<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
vocabulary<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span>
vocabulary <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>vocabulary<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>vocabulary<span class="token punctuation">)</span>  <span class="token comment"># ['_', 'a', 'b', 'd', 'e', 'g', 'i', 'j', 'n', 'o']</span>

<span class="token comment"># 根据语料构建词表</span>
corpus_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword keyword-for">for</span> token <span class="token keyword keyword-in">in</span> tokens<span class="token punctuation">:</span>
    key <span class="token operator">=</span> token <span class="token operator">+</span> <span class="token string">'_'</span>
    <span class="token keyword keyword-if">if</span> key <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> corpus_dict<span class="token punctuation">:</span>
        corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"split"</span><span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"count"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
    corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'count'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>  <span class="token comment"># 比如：'nan_': {'split': ['n', 'a', 'n', '_'], 'count': 5}</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"语料："</span></span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> corpus_dict<span class="token punctuation">:</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'count'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'split'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"词表：</span><span class="token interpolation"><span class="token punctuation">{</span>vocabulary<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># 2. BPE词元学习器</span>
<span class="token keyword keyword-for">for</span> step <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"------第</span><span class="token interpolation"><span class="token punctuation">{</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">次迭代------"</span></span><span class="token punctuation">)</span>
    split_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  <span class="token comment"># 用于统计符号组合的出现次数</span>
    <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> corpus_dict<span class="token punctuation">:</span>
        splits <span class="token operator">=</span> corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'split'</span><span class="token punctuation">]</span>  <span class="token comment"># key是当前符号nan_，splits是分割后的符号['n', 'a', 'n', '_']</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"当前符号：</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">}</span></span><span class="token string">, 分割后的符号：</span><span class="token interpolation"><span class="token punctuation">{</span>splits<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token comment"># 遍历所有符号进行统计</span>
        <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 组合两个符号作为新的符号</span>
            current_group <span class="token operator">=</span> splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> splits<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword keyword-if">if</span> current_group <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> split_dict<span class="token punctuation">:</span>
                split_dict<span class="token punctuation">[</span>current_group<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
            split_dict<span class="token punctuation">[</span>current_group<span class="token punctuation">]</span> <span class="token operator">+=</span> corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'count'</span><span class="token punctuation">]</span>

    group_hist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> k<span class="token punctuation">,</span> v <span class="token keyword keyword-in">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>split_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword keyword-lambda">lambda</span> item<span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"当前最常出现的前5个符号组合：</span><span class="token interpolation"><span class="token punctuation">{</span>group_hist<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">5]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    merge_key <span class="token operator">=</span> group_hist<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"本次迭代组合的符号为：</span><span class="token interpolation"><span class="token punctuation">{</span>merge_key<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> corpus_dict<span class="token punctuation">:</span>
        <span class="token keyword keyword-if">if</span> merge_key <span class="token keyword keyword-in">in</span> key<span class="token punctuation">:</span>
            new_splits <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            splits <span class="token operator">=</span> corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'split'</span><span class="token punctuation">]</span>
            i <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword keyword-while">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword keyword-if">if</span> i <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    i <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token keyword keyword-continue">continue</span>
                <span class="token keyword keyword-if">if</span> merge_key <span class="token operator">==</span> splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> splits<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>merge_key<span class="token punctuation">)</span>
                    i <span class="token operator">+=</span> <span class="token number">2</span>
                <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                    new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    i <span class="token operator">+=</span> <span class="token number">1</span>
            corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'split'</span><span class="token punctuation">]</span> <span class="token operator">=</span> new_splits  <span class="token comment"># 更新分割后的符号，比如merge_key是'ng'，那么之前的'n', 'g'会被替换为'ng'</span>

    vocabulary<span class="token punctuation">.</span>append<span class="token punctuation">(</span>merge_key<span class="token punctuation">)</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"迭代后的语料为："</span></span><span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> corpus_dict<span class="token punctuation">:</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'count'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> corpus_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'split'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"词表：</span><span class="token interpolation"><span class="token punctuation">{</span>vocabulary<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
ordered_vocabulary <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> i <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> key <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocabulary<span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token comment"># 3. BPE词元分词器</span>
sentence <span class="token operator">=</span> <span class="token string">"nanjing beijing"</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"--------输入语句：</span><span class="token interpolation"><span class="token punctuation">{</span>sentence<span class="token punctuation">}</span></span><span class="token string">--------"</span></span><span class="token punctuation">)</span>
tokens <span class="token operator">=</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
tokenized_string <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword keyword-for">for</span> token <span class="token keyword keyword-in">in</span> tokens<span class="token punctuation">:</span>
    key <span class="token operator">=</span> token <span class="token operator">+</span> <span class="token string">'_'</span>
    splits <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span>
    <span class="token comment"># 用于在没有更新的时候跳出</span>
    flag <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword keyword-while">while</span> flag<span class="token punctuation">:</span>
        flag <span class="token operator">=</span> <span class="token number">0</span>
        split_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment"># 遍历所有符号进行统计</span>
        <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 组合两个符号作为新的符号</span>
            current_group <span class="token operator">=</span> splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> splits<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword keyword-if">if</span> current_group <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> ordered_vocabulary<span class="token punctuation">:</span>
                <span class="token keyword keyword-continue">continue</span>  <span class="token comment"># 如果当前组合不在词表里，跳过</span>
            <span class="token keyword keyword-if">if</span> current_group <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> split_dict<span class="token punctuation">:</span>
                <span class="token comment"># 判断当前组合是否在词表里，如果是的话加入split_dict</span>
                split_dict<span class="token punctuation">[</span>current_group<span class="token punctuation">]</span> <span class="token operator">=</span> ordered_vocabulary<span class="token punctuation">[</span>current_group<span class="token punctuation">]</span>
                flag <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> flag<span class="token punctuation">:</span>
            <span class="token keyword keyword-continue">continue</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"当前分词：</span><span class="token interpolation"><span class="token punctuation">{</span>splits<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"当前组合：</span><span class="token interpolation"><span class="token punctuation">{</span>split_dict<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token comment"># 对每个组合进行优先级的排序（此处为从小到大）</span>
        group_hist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> k<span class="token punctuation">,</span> v <span class="token keyword keyword-in">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>split_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword keyword-lambda">lambda</span> item<span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment"># 优先级最高的组合</span>
        merge_key <span class="token operator">=</span> group_hist<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"当前优先级最高的</span><span class="token interpolation"><span class="token punctuation">{</span>merge_key<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        new_splits <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        i <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment"># 根据优先级最高的组合产生新的分词</span>
        <span class="token keyword keyword-while">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword keyword-if">if</span> i <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span><span class="token punctuation">:</span>
                new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                i <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword keyword-continue">continue</span>
            <span class="token keyword keyword-if">if</span> merge_key <span class="token operator">==</span> splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> splits<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>merge_key<span class="token punctuation">)</span>
                i <span class="token operator">+=</span> <span class="token number">2</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                new_splits<span class="token punctuation">.</span>append<span class="token punctuation">(</span>splits<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                i <span class="token operator">+=</span> <span class="token number">1</span>
        splits <span class="token operator">=</span> new_splits
    tokenized_string <span class="token operator">+=</span> splits

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"分词结果：</span><span class="token interpolation"><span class="token punctuation">{</span>tokenized_string<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre></details>
<h2 id="color66ccff-22-词规范化-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>2.2</mn><mtext>&nbsp;词规范化</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 2.2\ 词规范化</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">2.2</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">词规范化</span></span></span></span> </h2>
<h3 id="color39c5bb-221-英文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.2.1</mn><mtext>&nbsp;英文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.2.1\ 英文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.2.1</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">英文</span></span></span></span> </h3>
<ol>
<li><strong>大小写转换：</strong> <code>sentence.lower()</code></li>
<li><strong>词目还原：</strong> <code>nltk.WordNetLemmatizer().lemmatize(word, pos='v')</code>，其中<code>pos</code>是词性，比如<code>v</code>是动词。</li>
<li><strong>词干还原：</strong> <code>nltk.PorterStemmer().stem(word)</code></li>
</ol>
<h3 id="color39c5bb-222-中文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.2.2</mn><mtext>&nbsp;中文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.2.2\ 中文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.2.2</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">中文</span></span></span></span> </h3>
<ol>
<li><strong>繁简转换：</strong> <code>opencc</code>、<code>hanziconv</code></li>
</ol>
<h2 id="color66ccff-23-分句-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>2.3</mn><mtext>&nbsp;分句</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 2.3\ 分句</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">2.3</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">分句</span></span></span></span> </h2>
<h3 id="color39c5bb-231-英文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.3.1</mn><mtext>&nbsp;英文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.3.1\ 英文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.3.1</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">英文</span></span></span></span> </h3>
<ol>
<li><strong>基于正则表达式：</strong> <code>re.split(r'[.!?]', text)</code>，该方法可能会出现歧义，标点<code>.!?</code>可能会出现在缩写、数字、网址其他等地方。正确做法是先分词，再分句。如下：</li>
</ol>
<details>
<summary><span style="color:#009688; font-weight:bold">点击展开完整代码</span></summary>  
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> re
sentence_spliter <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"."</span><span class="token punctuation">,</span> <span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">'!'</span><span class="token punctuation">,</span> <span class="token string">'...'</span><span class="token punctuation">}</span>
sentence <span class="token operator">=</span> <span class="token string">"Did you spend $3.4 on arxiv.org for your pre-print? No, it's free! It's ..."</span>
pattern <span class="token operator">=</span> <span class="token string">r"\.\.\.|\$?\d+(?:\.\d+)?%?|(?:\w+\.)+\w+(?:\.)*|\w+(?:[-']\w+)*|\S\w*"</span>
tokens <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>
<span class="token comment"># ['Did', 'you', 'spend', '$3.4', 'on', 'arxiv.org', 'for', 'your', 'pre-print', '?', 'No', ',', "it's", 'free', '!', "It's", '...']</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
boundary <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># 遍历所有token，如果该token是句子边界，则将句子加入sentences</span>
<span class="token keyword keyword-for">for</span> token_id<span class="token punctuation">,</span> token <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-if">if</span> token <span class="token keyword keyword-in">in</span> sentence_spliter<span class="token punctuation">:</span>
        <span class="token comment"># 如果是句子边界，则把分句结果加入进去</span>
        sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span>boundary<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>token_id <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 将下一句句子起始位置加入boundary</span>
        boundary<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token_id <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># print(sentences)</span>
<span class="token comment"># 即使最后一个句子不是句子边界，也要加入进去</span>
<span class="token keyword keyword-if">if</span> boundary<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span>boundary<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"分句结果："</span></span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> seg_sentence <span class="token keyword keyword-in">in</span> sentences<span class="token punctuation">:</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>seg_sentence<span class="token punctuation">)</span>
</code></pre><p>输出：</p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>['Did', 'you', 'spend', '$3.4', 'on', 'arxiv.org', 'for', 'your', 'pre-print', '?']
['No', ',', "it's", 'free', '!']
["It's", '...']
</code></pre></details>
<h3 id="color39c5bb-232-中文-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#39c5bb"><mn>2.3.2</mn><mtext>&nbsp;中文</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{39c5bb} 2.3.2\ 中文</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#39c5bb;">2.3.2</span><span class="mspace" style="color:#39c5bb;"><span style="color:#39c5bb;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#39c5bb;">中文</span></span></span></span> </h3>
<ol>
<li><strong>基于正则表达式：</strong> <code>re.split(r'[。！？]', text)</code>，同样可能会出现歧义，正确做法是先分词，再分句。</li>
</ol>
<h1 id="coloree0000-3-文本表示-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#ee0000"><mn>3.</mn><mtext>&nbsp;文本表示</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{ee0000} 3.\ 文本表示</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#ee0000;">3.</span><span class="mspace" style="color:#ee0000;"><span style="color:#ee0000;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#ee0000;">文本表示</span></span></span></span> </h1>
<h2 id="color66ccff-31-词向量-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>3.1</mn><mtext>&nbsp;词向量</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 3.1\ 词向量</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">3.1</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">词向量</span></span></span></span> </h2>
<p>这里只给出GloVe的使用，不具体讨论词向量应该怎么表示更好。</p>
<details>
<summary><span style="color:#009688; font-weight:bold">点击展开完整代码</span></summary>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> pprint  <span class="token comment"># 美化输出</span>
<span class="token keyword keyword-from">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword keyword-import">import</span> KeyedVectors  <span class="token comment"># 加载词向量</span>

model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">'../model/official/glove/glove.6B.100d.txt'</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> no_header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># 使用most_similar()找到词表中距离给定词最近（最相似）的n个词</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">'film'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">'car'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 类比</span>
<span class="token keyword keyword-def">def</span> <span class="token function">analogy</span><span class="token punctuation">(</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y1<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># y1 + x2 - x1</span>
    result <span class="token operator">=</span> model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span>y1<span class="token punctuation">,</span> x2<span class="token punctuation">]</span><span class="token punctuation">,</span> negative<span class="token operator">=</span><span class="token punctuation">[</span>x1<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>analogy<span class="token punctuation">(</span><span class="token string">'china'</span><span class="token punctuation">,</span> <span class="token string">'chinese'</span><span class="token punctuation">,</span> <span class="token string">'japan'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># japanese</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>analogy<span class="token punctuation">(</span><span class="token string">'australia'</span><span class="token punctuation">,</span> <span class="token string">'koala'</span><span class="token punctuation">,</span> <span class="token string">'china'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># panda</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>analogy<span class="token punctuation">(</span><span class="token string">'tall'</span><span class="token punctuation">,</span> <span class="token string">'tallest'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># longest</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>analogy<span class="token punctuation">(</span><span class="token string">'good'</span><span class="token punctuation">,</span> <span class="token string">'fantastic'</span><span class="token punctuation">,</span> <span class="token string">'bad'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># terrible</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>analogy<span class="token punctuation">(</span><span class="token string">'man'</span><span class="token punctuation">,</span> <span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'king'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># queen</span>
</code></pre></details>
<h2 id="color66ccff-32-稀疏向量-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>3.2</mn><mtext>&nbsp;稀疏向量</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 3.2\ 稀疏向量</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">3.2</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">稀疏向量</span></span></span></span> </h2>
<h2 id="color66ccff-33-稠密向量-"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="#66ccff"><mn>3.3</mn><mtext>&nbsp;稠密向量</mtext></mstyle></mrow><annotation encoding="application/x-tex">\color{66ccff} 3.3\ 稠密向量</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:#66ccff;">3.3</span><span class="mspace" style="color:#66ccff;"><span style="color:#66ccff;">&nbsp;</span></span><span class="mord cjk_fallback" style="color:#66ccff;">稠密向量</span></span></span></span> </h2>
<p>word2vec在<a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html">推荐系统2.2.1</a>里，这里只给出pytorch的实现。</p>
<details>
<summary><span style="color:#009688; font-weight:bold">点击展开完整代码</span></summary>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword keyword-import">import</span> sent_tokenize<span class="token punctuation">,</span> word_tokenize
<span class="token keyword keyword-from">from</span> collections <span class="token keyword keyword-import">import</span> defaultdict
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-import">import</span> torch
<span class="token keyword keyword-from">from</span> torch <span class="token keyword keyword-import">import</span> nn
<span class="token keyword keyword-import">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword keyword-as">as</span> F
<span class="token keyword keyword-from">from</span> tqdm <span class="token keyword keyword-import">import</span> trange
<span class="token keyword keyword-import">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword keyword-as">as</span> plt
<span class="token keyword keyword-from">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword keyword-import">import</span> DataLoader
<span class="token keyword keyword-from">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword keyword-import">import</span> Adam

<span class="token comment"># 使用类管理数据对象，包括文本读取、文本预处理等</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">TheLittlePrinceDataset</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokenize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 利用NLTK函数进行分句和分词</span>
        text <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/the little prince.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> tokenize<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>sentences <span class="token operator">=</span> sent_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>tokens <span class="token operator">=</span> <span class="token punctuation">[</span>word_tokenize<span class="token punctuation">(</span>sent<span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> sent <span class="token keyword keyword-in">in</span> self<span class="token punctuation">.</span>sentences<span class="token punctuation">]</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>text <span class="token operator">=</span> text

    <span class="token keyword keyword-def">def</span> <span class="token function">build_vocab</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> min_freq<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 统计词频</span>
        frequency <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-for">for</span> sentence <span class="token keyword keyword-in">in</span> self<span class="token punctuation">.</span>tokens<span class="token punctuation">:</span>
            <span class="token keyword keyword-for">for</span> token <span class="token keyword keyword-in">in</span> sentence<span class="token punctuation">:</span>
                frequency<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>frequency <span class="token operator">=</span> frequency

        <span class="token comment"># 加入&lt;unk&gt;处理未登录词，加入&lt;pad&gt;用于对齐变长输入进而加速</span>
        self<span class="token punctuation">.</span>token2id <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>id2token <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">}</span>
        <span class="token keyword keyword-for">for</span> token<span class="token punctuation">,</span> freq <span class="token keyword keyword-in">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>frequency<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword keyword-lambda">lambda</span> x<span class="token punctuation">:</span> <span class="token operator">-</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 丢弃低频词</span>
            <span class="token keyword keyword-if">if</span> freq <span class="token operator">&gt;</span> min_freq<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>token2id<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>token2id<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>id2token<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>id2token<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> token
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                <span class="token keyword keyword-break">break</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">get_word_distribution</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        distribution <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span>
        <span class="token keyword keyword-for">for</span> token<span class="token punctuation">,</span> freq <span class="token keyword keyword-in">in</span> self<span class="token punctuation">.</span>frequency<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword keyword-if">if</span> token <span class="token keyword keyword-in">in</span> dataset<span class="token punctuation">.</span>token2id<span class="token punctuation">:</span>
                distribution<span class="token punctuation">[</span>dataset<span class="token punctuation">.</span>token2id<span class="token punctuation">[</span>token<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> freq
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                <span class="token comment"># 不在词表中的词按&lt;unk&gt;计算</span>
                distribution<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> freq
        distribution <span class="token operator">/=</span> distribution<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> distribution

    <span class="token comment"># 将分词结果转化为索引表示</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">convert_tokens_to_ids</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> drop_single_word<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>token_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword keyword-for">for</span> sentence <span class="token keyword keyword-in">in</span> self<span class="token punctuation">.</span>tokens<span class="token punctuation">:</span>
            token_ids <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>token2id<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> token <span class="token keyword keyword-in">in</span> sentence<span class="token punctuation">]</span>
            <span class="token comment"># 忽略只有一个token的序列，无法计算loss</span>
            <span class="token keyword keyword-if">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword keyword-and">and</span> drop_single_word<span class="token punctuation">:</span>
                <span class="token keyword keyword-continue">continue</span>
            self<span class="token punctuation">.</span>token_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token_ids<span class="token punctuation">)</span>

        <span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>token_ids

dataset <span class="token operator">=</span> TheLittlePrinceDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>build_vocab<span class="token punctuation">(</span>min_freq<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
sentences <span class="token operator">=</span> dataset<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 遍历所有的中心词-上下文词对</span>
window_size <span class="token operator">=</span> <span class="token number">2</span>
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 存储中心词-上下文词对</span>
<span class="token keyword keyword-for">for</span> sentence <span class="token keyword keyword-in">in</span> sentences<span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-for">for</span> j <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>i<span class="token operator">-</span>window_size<span class="token punctuation">,</span> i<span class="token operator">+</span>window_size<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword keyword-if">if</span> j <span class="token operator">==</span> i <span class="token keyword keyword-or">or</span> j <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token keyword keyword-or">or</span> j <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword keyword-continue">continue</span>
            center_word <span class="token operator">=</span> sentence<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            context_word <span class="token operator">=</span> sentence<span class="token punctuation">[</span>j<span class="token punctuation">]</span>
            data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>center_word<span class="token punctuation">,</span> context_word<span class="token punctuation">]</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> data<span class="token punctuation">)</span>

<span class="token comment"># 实现skipgram算法，使用对比学习计算损失</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">SkipGramNCE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> distribution<span class="token punctuation">,</span> neg_samples<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SkipGramNCE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'vocab_size = </span><span class="token interpolation"><span class="token punctuation">{</span>vocab_size<span class="token punctuation">}</span></span><span class="token string">, embed_size = </span><span class="token interpolation"><span class="token punctuation">{</span>embed_size<span class="token punctuation">}</span></span><span class="token string">, '</span></span> <span class="token operator">+</span> <span class="token string-interpolation"><span class="token string">f'neg_samples = </span><span class="token interpolation"><span class="token punctuation">{</span>neg_samples<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_embeddings <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output_embeddings <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>
        distribution <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>distribution<span class="token punctuation">,</span> <span class="token number">0.75</span><span class="token punctuation">)</span>
        distribution <span class="token operator">/=</span> distribution<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>distribution<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>neg_samples <span class="token operator">=</span> neg_samples

    <span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_ids<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        i_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>input_embeddings<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
        o_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>output_embeddings<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
        batch_size <span class="token operator">=</span> i_embed<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        n_words <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>self<span class="token punctuation">.</span>distribution<span class="token punctuation">,</span> batch_size <span class="token operator">*</span> self<span class="token punctuation">.</span>neg_samples<span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        n_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>output_embeddings<span class="token punctuation">(</span>n_words<span class="token punctuation">)</span>
        pos_term <span class="token operator">=</span> F<span class="token punctuation">.</span>logsigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>i_embed <span class="token operator">*</span> o_embed<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 负采样，用于对比学习</span>
        neg_term <span class="token operator">=</span> F<span class="token punctuation">.</span>logsigmoid<span class="token punctuation">(</span><span class="token operator">-</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>n_embed<span class="token punctuation">,</span> i_embed<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        neg_term <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>neg_term<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>pos_term <span class="token operator">+</span> neg_term<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> loss


<span class="token comment"># 为对比学习负采样准备词频率分布</span>
vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>token2id<span class="token punctuation">)</span>
embed_size <span class="token operator">=</span> <span class="token number">128</span>
distribution <span class="token operator">=</span> dataset<span class="token punctuation">.</span>get_word_distribution<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>distribution<span class="token punctuation">)</span>
model <span class="token operator">=</span> SkipGramNCE<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> distribution<span class="token punctuation">)</span>


<span class="token comment"># 定义静态方法collate_batch批量处理数据，转化为PyTorch可以需要的张量类型</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">DataCollator</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">collate_batch</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
        input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> <span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> input_ids<span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">:</span> labels<span class="token punctuation">}</span>


<span class="token comment"># 定义训练参数以及训练循环</span>
epochs <span class="token operator">=</span> <span class="token number">100</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
learning_rate <span class="token operator">=</span> <span class="token number">1e-3</span>
epoch_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

data_collator <span class="token operator">=</span> DataCollator<span class="token punctuation">(</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>data_collator<span class="token punctuation">.</span>collate_batch<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练过程，每步读取数据，送入模型计算损失，并使用PyTorch进行优化</span>
<span class="token keyword keyword-with">with</span> trange<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">'epoch'</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">)</span> <span class="token keyword keyword-as">as</span> pbar<span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> epoch <span class="token keyword keyword-in">in</span> pbar<span class="token punctuation">:</span>
        <span class="token keyword keyword-for">for</span> step<span class="token punctuation">,</span> batch <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            loss <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
            pbar<span class="token punctuation">.</span>set_description<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'epoch-</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string">, loss=</span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

epoch_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch_loss<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'training epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 保存模型</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'../model/prince/skipgram_nce.pth'</span><span class="token punctuation">)</span>
<span class="token comment"># 保存词向量</span>
embeddings <span class="token operator">=</span> model<span class="token punctuation">.</span>input_embeddings<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'../model/prince/embeddings.npy'</span><span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>
<span class="token comment"># 查询happy和sad的词向量，然后计算它们的余弦相似度</span>
happy <span class="token operator">=</span> embeddings<span class="token punctuation">[</span>dataset<span class="token punctuation">.</span>token2id<span class="token punctuation">[</span><span class="token string">'happy'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
sad <span class="token operator">=</span> embeddings<span class="token punctuation">[</span>dataset<span class="token punctuation">.</span>token2id<span class="token punctuation">[</span><span class="token string">'sad'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
similarity <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>happy<span class="token punctuation">,</span> sad<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>happy<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>sad<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>similarity<span class="token punctuation">)</span>  <span class="token comment"># 0.05455044</span>
</code></pre></details>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>